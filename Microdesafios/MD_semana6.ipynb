{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from requests import status_codes\n",
    "\n",
    "from pytrends import exceptions\n",
    "\n",
    "from urllib.parse import quote\n",
    "\n",
    "BASE_TRENDS_URL = 'https://trends.google.com/trends'\n",
    "\n",
    "\n",
    "class TrendReq(object):\n",
    "    \"\"\"\n",
    "    Google Trends API\n",
    "    \"\"\"\n",
    "    GET_METHOD = 'get'\n",
    "    POST_METHOD = 'post'\n",
    "    GENERAL_URL = f'{BASE_TRENDS_URL}/api/explore'\n",
    "    INTEREST_OVER_TIME_URL = f'{BASE_TRENDS_URL}/api/widgetdata/multiline'\n",
    "    MULTIRANGE_INTEREST_OVER_TIME_URL = f'{BASE_TRENDS_URL}/api/widgetdata/multirange'\n",
    "    INTEREST_BY_REGION_URL = f'{BASE_TRENDS_URL}/api/widgetdata/comparedgeo'\n",
    "    RELATED_QUERIES_URL = f'{BASE_TRENDS_URL}/api/widgetdata/relatedsearches'\n",
    "    TRENDING_SEARCHES_URL = f'{BASE_TRENDS_URL}/hottrends/visualize/internal/data'\n",
    "    TOP_CHARTS_URL = f'{BASE_TRENDS_URL}/api/topcharts'\n",
    "    SUGGESTIONS_URL = f'{BASE_TRENDS_URL}/api/autocomplete/'\n",
    "    CATEGORIES_URL = f'{BASE_TRENDS_URL}/api/explore/pickers/category'\n",
    "    TODAY_SEARCHES_URL = f'{BASE_TRENDS_URL}/api/dailytrends'\n",
    "    REALTIME_TRENDING_SEARCHES_URL = f'{BASE_TRENDS_URL}/api/realtimetrends'\n",
    "    ERROR_CODES = (500, 502, 504, 429)\n",
    "\n",
    "    def __init__(self, hl='en-US', tz=360, geo='', timeout=(2, 5), proxies='',\n",
    "                 retries=0, backoff_factor=0, requests_args=None):\n",
    "        \"\"\"\n",
    "        Initialize default values for params\n",
    "        \"\"\"\n",
    "        # google rate limit\n",
    "        self.google_rl = 'You have reached your quota limit. Please try again later.'\n",
    "        self.results = None\n",
    "        # set user defined options used globally\n",
    "        self.tz = tz\n",
    "        self.hl = hl\n",
    "        self.geo = geo\n",
    "        self.kw_list = list()\n",
    "        self.timeout = timeout\n",
    "        self.proxies = proxies  # add a proxy option\n",
    "        self.retries = retries\n",
    "        self.backoff_factor = backoff_factor\n",
    "        self.proxy_index = 0\n",
    "        self.requests_args = requests_args or {}\n",
    "        self.cookies = self.GetGoogleCookie()\n",
    "        # intialize widget payloads\n",
    "        self.token_payload = dict()\n",
    "        self.interest_over_time_widget = dict()\n",
    "        self.interest_by_region_widget = dict()\n",
    "        self.related_topics_widget_list = list()\n",
    "        self.related_queries_widget_list = list()\n",
    "\n",
    "        self.headers = {'accept-language': self.hl}\n",
    "        self.headers.update(self.requests_args.pop('headers', {}))\n",
    "        \n",
    "    def GetGoogleCookie(self):\n",
    "        \"\"\"\n",
    "        Gets google cookie (used for each and every proxy; once on init otherwise)\n",
    "        Removes proxy from the list on proxy error\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            if \"proxies\" in self.requests_args:\n",
    "                try:\n",
    "                    return dict(filter(lambda i: i[0] == 'NID', requests.post(\n",
    "                        f'{BASE_TRENDS_URL}/?geo={self.hl[-2:]}',\n",
    "                        timeout=self.timeout,\n",
    "                        **self.requests_args\n",
    "                    ).cookies.items()))\n",
    "                except:\n",
    "                    continue\n",
    "            else:\n",
    "                if len(self.proxies) > 0:\n",
    "                    proxy = {'https': self.proxies[self.proxy_index]}\n",
    "                else:\n",
    "                    proxy = ''\n",
    "                try:\n",
    "                    return dict(filter(lambda i: i[0] == 'NID', requests.post(\n",
    "                        f'{BASE_TRENDS_URL}/?geo={self.hl[-2:]}',\n",
    "                        timeout=self.timeout,\n",
    "                        proxies=proxy,\n",
    "                        **self.requests_args\n",
    "                    ).cookies.items()))\n",
    "                except requests.exceptions.ProxyError:\n",
    "                    print('Proxy error. Changing IP')\n",
    "                    if len(self.proxies) > 1:\n",
    "                        self.proxies.remove(self.proxies[self.proxy_index])\n",
    "                    else:\n",
    "                        print('No more proxies available. Bye!')\n",
    "                        raise\n",
    "                    continue\n",
    "\n",
    "    def GetNewProxy(self):\n",
    "        \"\"\"\n",
    "        Increment proxy INDEX; zero on overflow\n",
    "        \"\"\"\n",
    "        if self.proxy_index < (len(self.proxies) - 1):\n",
    "            self.proxy_index += 1\n",
    "        else:\n",
    "            self.proxy_index = 0\n",
    "\n",
    "    def _get_data(self, url, method=GET_METHOD, trim_chars=0, **kwargs):\n",
    "        \"\"\"Send a request to Google and return the JSON response as a Python object\n",
    "        :param url: the url to which the request will be sent\n",
    "        :param method: the HTTP method ('get' or 'post')\n",
    "        :param trim_chars: how many characters should be trimmed off the beginning of the content of the response\n",
    "            before this is passed to the JSON parser\n",
    "        :param kwargs: any extra key arguments passed to the request builder (usually query parameters or data)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        s = requests.session()\n",
    "        # Retries mechanism. Activated when one of statements >0 (best used for proxy)\n",
    "        if self.retries > 0 or self.backoff_factor > 0:\n",
    "            retry = Retry(total=self.retries, read=self.retries,\n",
    "                          connect=self.retries,\n",
    "                          backoff_factor=self.backoff_factor,\n",
    "                          status_forcelist=TrendReq.ERROR_CODES,\n",
    "                          allowed_methods=frozenset(['GET', 'POST']))\n",
    "            s.mount('https://', HTTPAdapter(max_retries=retry))\n",
    "\n",
    "        s.headers.update(self.headers)\n",
    "        if len(self.proxies) > 0:\n",
    "            self.cookies = self.GetGoogleCookie()\n",
    "            s.proxies.update({'https': self.proxies[self.proxy_index]})\n",
    "        if method == TrendReq.POST_METHOD:\n",
    "            response = s.post(url, timeout=self.timeout,\n",
    "                              cookies=self.cookies, **kwargs,\n",
    "                              **self.requests_args)  # DO NOT USE retries or backoff_factor here\n",
    "        else:\n",
    "            response = s.get(url, timeout=self.timeout, cookies=self.cookies,\n",
    "                             **kwargs, **self.requests_args)  # DO NOT USE retries or backoff_factor here\n",
    "        # check if the response contains json and throw an exception otherwise\n",
    "        # Google mostly sends 'application/json' in the Content-Type header,\n",
    "        # but occasionally it sends 'application/javascript\n",
    "        # and sometimes even 'text/javascript\n",
    "        if response.status_code == 200 and 'application/json' in \\\n",
    "                response.headers['Content-Type'] or \\\n",
    "                'application/javascript' in response.headers['Content-Type'] or \\\n",
    "                'text/javascript' in response.headers['Content-Type']:\n",
    "            # trim initial characters\n",
    "            # some responses start with garbage characters, like \")]}',\"\n",
    "            # these have to be cleaned before being passed to the json parser\n",
    "            content = response.text[trim_chars:]\n",
    "            # parse json\n",
    "            self.GetNewProxy()\n",
    "            return json.loads(content)\n",
    "        else:\n",
    "            if response.status_code == status_codes.codes.too_many_requests:\n",
    "                raise exceptions.TooManyRequestsError.from_response(response)\n",
    "            raise exceptions.ResponseError.from_response(response)\n",
    "\n",
    "    def build_payload(self, kw_list, cat=0, timeframe='today 5-y', geo='',\n",
    "                      gprop=''):\n",
    "        \"\"\"Create the payload for related queries, interest over time and interest by region\"\"\"\n",
    "        if gprop not in ['', 'images', 'news', 'youtube', 'froogle']:\n",
    "            raise ValueError('gprop must be empty (to indicate web), images, news, youtube, or froogle')\n",
    "        self.kw_list = kw_list\n",
    "        self.geo = geo or self.geo\n",
    "        self.token_payload = {\n",
    "            'hl': self.hl,\n",
    "            'tz': self.tz,\n",
    "            'req': {'comparisonItem': [], 'category': cat, 'property': gprop}\n",
    "        }\n",
    "\n",
    "        # Check if timeframe is a list\n",
    "        if isinstance(timeframe, list):\n",
    "            for index, kw in enumerate(self.kw_list):\n",
    "                keyword_payload = {'keyword': kw, 'time': timeframe[index], 'geo': self.geo}\n",
    "                self.token_payload['req']['comparisonItem'].append(keyword_payload)\n",
    "        else: \n",
    "            # build out json for each keyword with\n",
    "            for kw in self.kw_list:\n",
    "                keyword_payload = {'keyword': kw, 'time': timeframe, 'geo': self.geo}\n",
    "                self.token_payload['req']['comparisonItem'].append(keyword_payload)\n",
    "\n",
    "        # requests will mangle this if it is not a string\n",
    "        self.token_payload['req'] = json.dumps(self.token_payload['req'])\n",
    "        # get tokens\n",
    "        self._tokens()\n",
    "        return\n",
    "\n",
    "    def _tokens(self):\n",
    "        \"\"\"Makes request to Google to get API tokens for interest over time, interest by region and related queries\"\"\"\n",
    "        # make the request and parse the returned json\n",
    "        widget_dicts = self._get_data(\n",
    "            url=TrendReq.GENERAL_URL,\n",
    "            method=TrendReq.GET_METHOD,\n",
    "            params=self.token_payload,\n",
    "            trim_chars=4,\n",
    "        )['widgets']\n",
    "        # order of the json matters...\n",
    "        first_region_token = True\n",
    "        # clear self.related_queries_widget_list and self.related_topics_widget_list\n",
    "        # of old keywords'widgets\n",
    "        self.related_queries_widget_list[:] = []\n",
    "        self.related_topics_widget_list[:] = []\n",
    "        # assign requests\n",
    "        for widget in widget_dicts:\n",
    "            if widget['id'] == 'TIMESERIES':\n",
    "                self.interest_over_time_widget = widget\n",
    "            if widget['id'] == 'GEO_MAP' and first_region_token:\n",
    "                self.interest_by_region_widget = widget\n",
    "                first_region_token = False\n",
    "            # response for each term, put into a list\n",
    "            if 'RELATED_TOPICS' in widget['id']:\n",
    "                self.related_topics_widget_list.append(widget)\n",
    "            if 'RELATED_QUERIES' in widget['id']:\n",
    "                self.related_queries_widget_list.append(widget)\n",
    "        return\n",
    "\n",
    "    def interest_over_time(self):\n",
    "        \"\"\"Request data from Google's Interest Over Time section and return a dataframe\"\"\"\n",
    "\n",
    "        over_time_payload = {\n",
    "            # convert to string as requests will mangle\n",
    "            'req': json.dumps(self.interest_over_time_widget['request']),\n",
    "            'token': self.interest_over_time_widget['token'],\n",
    "            'tz': self.tz\n",
    "        }\n",
    "\n",
    "        # make the request and parse the returned json\n",
    "        req_json = self._get_data(\n",
    "            url=TrendReq.INTEREST_OVER_TIME_URL,\n",
    "            method=TrendReq.GET_METHOD,\n",
    "            trim_chars=5,\n",
    "            params=over_time_payload,\n",
    "        )\n",
    "\n",
    "        df = pd.DataFrame(req_json['default']['timelineData'])\n",
    "        if (df.empty):\n",
    "            return df\n",
    "\n",
    "        df['date'] = pd.to_datetime(df['time'].astype(dtype='float64'),\n",
    "                                    unit='s')\n",
    "        df = df.set_index(['date']).sort_index()\n",
    "        # split list columns into seperate ones, remove brackets and split on comma\n",
    "        result_df = df['value'].apply(lambda x: pd.Series(\n",
    "            str(x).replace('[', '').replace(']', '').split(',')))\n",
    "        # rename each column with its search term, relying on order that google provides...\n",
    "        for idx, kw in enumerate(self.kw_list):\n",
    "            # there is currently a bug with assigning columns that may be\n",
    "            # parsed as a date in pandas: use explicit insert column method\n",
    "            result_df.insert(len(result_df.columns), kw,\n",
    "                             result_df[idx].astype('int'))\n",
    "            del result_df[idx]\n",
    "\n",
    "        if 'isPartial' in df:\n",
    "            # make other dataframe from isPartial key data\n",
    "            # split list columns into seperate ones, remove brackets and split on comma\n",
    "            df = df.fillna(False)\n",
    "            result_df2 = df['isPartial'].apply(lambda x: pd.Series(\n",
    "                str(x).replace('[', '').replace(']', '').split(',')))\n",
    "            result_df2.columns = ['isPartial']\n",
    "            # Change to a bool type.\n",
    "            result_df2.isPartial = result_df2.isPartial == 'True'\n",
    "            # concatenate the two dataframes\n",
    "            final = pd.concat([result_df, result_df2], axis=1)\n",
    "        else:\n",
    "            final = result_df\n",
    "            final['isPartial'] = False\n",
    "\n",
    "        return final\n",
    "\n",
    "    def multirange_interest_over_time(self):\n",
    "        \"\"\"Request data from Google's Interest Over Time section across different time ranges and return a dataframe\"\"\"\n",
    "\n",
    "        over_time_payload = {\n",
    "            # convert to string as requests will mangle\n",
    "            'req': json.dumps(self.interest_over_time_widget['request']),\n",
    "            'token': self.interest_over_time_widget['token'],\n",
    "            'tz': self.tz\n",
    "        }\n",
    "\n",
    "        # make the request and parse the returned json\n",
    "        req_json = self._get_data(\n",
    "            url=TrendReq.MULTIRANGE_INTEREST_OVER_TIME_URL,\n",
    "            method=TrendReq.GET_METHOD,\n",
    "            trim_chars=5,\n",
    "            params=over_time_payload,\n",
    "        )\n",
    "\n",
    "        df = pd.DataFrame(req_json['default']['timelineData'])\n",
    "        if (df.empty):\n",
    "            return df\n",
    "\n",
    "        result_df = pd.json_normalize(df['columnData'])\n",
    "\n",
    "        # Split dictionary columns into seperate ones\n",
    "        for i, column in enumerate(result_df.columns):\n",
    "            result_df[\"[\" + str(i) + \"] \" + str(self.kw_list[i]) + \" date\"] = result_df[i].apply(pd.Series)[\"formattedTime\"]\n",
    "            result_df[\"[\" + str(i) + \"] \" + str(self.kw_list[i]) + \" value\"] = result_df[i].apply(pd.Series)[\"value\"]   \n",
    "            result_df = result_df.drop([i], axis=1)\n",
    "        \n",
    "        # Adds a row with the averages at the top of the dataframe\n",
    "        avg_row = {}\n",
    "        for i, avg in enumerate(req_json['default']['averages']):\n",
    "            avg_row[\"[\" + str(i) + \"] \" + str(self.kw_list[i]) + \" date\"] = \"Average\"\n",
    "            avg_row[\"[\" + str(i) + \"] \" + str(self.kw_list[i]) + \" value\"] = req_json['default']['averages'][i]\n",
    "\n",
    "        result_df.loc[-1] = avg_row\n",
    "        result_df.index = result_df.index + 1\n",
    "        result_df = result_df.sort_index()\n",
    "        \n",
    "        return result_df\n",
    "\n",
    "\n",
    "    def interest_by_region(self, resolution='COUNTRY', inc_low_vol=False,\n",
    "                           inc_geo_code=False):\n",
    "        \"\"\"Request data from Google's Interest by Region section and return a dataframe\"\"\"\n",
    "\n",
    "        # make the request\n",
    "        region_payload = dict()\n",
    "        if self.geo == '':\n",
    "            self.interest_by_region_widget['request'][\n",
    "                'resolution'] = resolution\n",
    "        elif self.geo == 'US' and resolution in ['DMA', 'CITY', 'REGION']:\n",
    "            self.interest_by_region_widget['request'][\n",
    "                'resolution'] = resolution\n",
    "\n",
    "        self.interest_by_region_widget['request'][\n",
    "            'includeLowSearchVolumeGeos'] = inc_low_vol\n",
    "\n",
    "        # convert to string as requests will mangle\n",
    "        region_payload['req'] = json.dumps(\n",
    "            self.interest_by_region_widget['request'])\n",
    "        region_payload['token'] = self.interest_by_region_widget['token']\n",
    "        region_payload['tz'] = self.tz\n",
    "\n",
    "        # parse returned json\n",
    "        req_json = self._get_data(\n",
    "            url=TrendReq.INTEREST_BY_REGION_URL,\n",
    "            method=TrendReq.GET_METHOD,\n",
    "            trim_chars=5,\n",
    "            params=region_payload,\n",
    "        )\n",
    "        df = pd.DataFrame(req_json['default']['geoMapData'])\n",
    "        if (df.empty):\n",
    "            return df\n",
    "\n",
    "        # rename the column with the search keyword\n",
    "        geo_column = 'geoCode' if 'geoCode' in df.columns else 'coordinates'\n",
    "        columns = ['geoName', geo_column, 'value']\n",
    "        df = df[columns].set_index(['geoName']).sort_index()\n",
    "        # split list columns into separate ones, remove brackets and split on comma\n",
    "        result_df = df['value'].apply(lambda x: pd.Series(\n",
    "            str(x).replace('[', '').replace(']', '').split(',')))\n",
    "        if inc_geo_code:\n",
    "            if geo_column in df.columns:\n",
    "                result_df[geo_column] = df[geo_column]\n",
    "            else:\n",
    "                print('Could not find geo_code column; Skipping')\n",
    "\n",
    "        # rename each column with its search term\n",
    "        for idx, kw in enumerate(self.kw_list):\n",
    "            result_df[kw] = result_df[idx].astype('int')\n",
    "            del result_df[idx]\n",
    "\n",
    "        return result_df\n",
    "\n",
    "    def related_topics(self):\n",
    "        \"\"\"Request data from Google's Related Topics section and return a dictionary of dataframes\n",
    "        If no top and/or rising related topics are found, the value for the key \"top\" and/or \"rising\" will be None\n",
    "        \"\"\"\n",
    "\n",
    "        # make the request\n",
    "        related_payload = dict()\n",
    "        result_dict = dict()\n",
    "        for request_json in self.related_topics_widget_list:\n",
    "            # ensure we know which keyword we are looking at rather than relying on order\n",
    "            try:\n",
    "                kw = request_json['request']['restriction'][\n",
    "                    'complexKeywordsRestriction']['keyword'][0]['value']\n",
    "            except KeyError:\n",
    "                kw = ''\n",
    "            # convert to string as requests will mangle\n",
    "            related_payload['req'] = json.dumps(request_json['request'])\n",
    "            related_payload['token'] = request_json['token']\n",
    "            related_payload['tz'] = self.tz\n",
    "\n",
    "            # parse the returned json\n",
    "            req_json = self._get_data(\n",
    "                url=TrendReq.RELATED_QUERIES_URL,\n",
    "                method=TrendReq.GET_METHOD,\n",
    "                trim_chars=5,\n",
    "                params=related_payload,\n",
    "            )\n",
    "\n",
    "            # top topics\n",
    "            try:\n",
    "                top_list = req_json['default']['rankedList'][0]['rankedKeyword']\n",
    "                df_top = pd.json_normalize(top_list, sep='_')\n",
    "            except KeyError:\n",
    "                # in case no top topics are found, the lines above will throw a KeyError\n",
    "                df_top = None\n",
    "\n",
    "            # rising topics\n",
    "            try:\n",
    "                rising_list = req_json['default']['rankedList'][1]['rankedKeyword']\n",
    "                df_rising = pd.json_normalize(rising_list, sep='_')\n",
    "            except KeyError:\n",
    "                # in case no rising topics are found, the lines above will throw a KeyError\n",
    "                df_rising = None\n",
    "\n",
    "            result_dict[kw] = {'rising': df_rising, 'top': df_top}\n",
    "        return result_dict\n",
    "\n",
    "    def related_queries(self):\n",
    "        \"\"\"Request data from Google's Related Queries section and return a dictionary of dataframes\n",
    "        If no top and/or rising related queries are found, the value for the key \"top\" and/or \"rising\" will be None\n",
    "        \"\"\"\n",
    "\n",
    "        # make the request\n",
    "        related_payload = dict()\n",
    "        result_dict = dict()\n",
    "        for request_json in self.related_queries_widget_list:\n",
    "            # ensure we know which keyword we are looking at rather than relying on order\n",
    "            try:\n",
    "                kw = request_json['request']['restriction'][\n",
    "                    'complexKeywordsRestriction']['keyword'][0]['value']\n",
    "            except KeyError:\n",
    "                kw = ''\n",
    "            # convert to string as requests will mangle\n",
    "            related_payload['req'] = json.dumps(request_json['request'])\n",
    "            related_payload['token'] = request_json['token']\n",
    "            related_payload['tz'] = self.tz\n",
    "\n",
    "            # parse the returned json\n",
    "            req_json = self._get_data(\n",
    "                url=TrendReq.RELATED_QUERIES_URL,\n",
    "                method=TrendReq.GET_METHOD,\n",
    "                trim_chars=5,\n",
    "                params=related_payload,\n",
    "            )\n",
    "\n",
    "            # top queries\n",
    "            try:\n",
    "                top_df = pd.DataFrame(\n",
    "                    req_json['default']['rankedList'][0]['rankedKeyword'])\n",
    "                top_df = top_df[['query', 'value']]\n",
    "            except KeyError:\n",
    "                # in case no top queries are found, the lines above will throw a KeyError\n",
    "                top_df = None\n",
    "\n",
    "            # rising queries\n",
    "            try:\n",
    "                rising_df = pd.DataFrame(\n",
    "                    req_json['default']['rankedList'][1]['rankedKeyword'])\n",
    "                rising_df = rising_df[['query', 'value']]\n",
    "            except KeyError:\n",
    "                # in case no rising queries are found, the lines above will throw a KeyError\n",
    "                rising_df = None\n",
    "\n",
    "            result_dict[kw] = {'top': top_df, 'rising': rising_df}\n",
    "        return result_dict\n",
    "\n",
    "    def trending_searches(self, pn='united_states'):\n",
    "        \"\"\"Request data from Google's Hot Searches section and return a dataframe\"\"\"\n",
    "\n",
    "        # make the request\n",
    "        # forms become obsolete due to the new TRENDING_SEARCHES_URL\n",
    "        # forms = {'ajax': 1, 'pn': pn, 'htd': '', 'htv': 'l'}\n",
    "        req_json = self._get_data(\n",
    "            url=TrendReq.TRENDING_SEARCHES_URL,\n",
    "            method=TrendReq.GET_METHOD\n",
    "        )[pn]\n",
    "        result_df = pd.DataFrame(req_json)\n",
    "        return result_df\n",
    "\n",
    "    def today_searches(self, pn='US'):\n",
    "        \"\"\"Request data from Google Daily Trends section and returns a dataframe\"\"\"\n",
    "        forms = {'ns': 15, 'geo': pn, 'tz': '-180', 'hl': 'en-US'}\n",
    "        req_json = self._get_data(\n",
    "            url=TrendReq.TODAY_SEARCHES_URL,\n",
    "            method=TrendReq.GET_METHOD,\n",
    "            trim_chars=5,\n",
    "            params=forms,\n",
    "            **self.requests_args\n",
    "        )['default']['trendingSearchesDays'][0]['trendingSearches']\n",
    "        # parse the returned json\n",
    "        result_df = pd.DataFrame(trend['title'] for trend in req_json)\n",
    "        return result_df.iloc[:, -1]\n",
    "\n",
    "    def realtime_trending_searches(self, pn='US', cat='all', count =300):\n",
    "        \"\"\"Request data from Google Realtime Search Trends section and returns a dataframe\"\"\"\n",
    "        # Don't know what some of the params mean here, followed the nodejs library\n",
    "        # https://github.com/pat310/google-trends-api/ 's implemenration\n",
    "\n",
    "\n",
    "        #sort: api accepts only 0 as the value, optional parameter\n",
    "\n",
    "        # ri: number of trending stories IDs returned,\n",
    "        # max value of ri supported is 300, based on emperical evidence\n",
    "\n",
    "        ri_value = 300\n",
    "        if count < ri_value:\n",
    "            ri_value = count\n",
    "\n",
    "        # rs : don't know what is does but it's max value is never more than the ri_value based on emperical evidence\n",
    "        # max value of ri supported is 200, based on emperical evidence\n",
    "        rs_value = 200\n",
    "        if count < rs_value:\n",
    "            rs_value = count-1\n",
    "\n",
    "        forms = {'ns': 15, 'geo': pn, 'tz': '300', 'hl': 'en-US', 'cat': cat, 'fi' : '0', 'fs' : '0', 'ri' : ri_value, 'rs' : rs_value, 'sort' : 0}\n",
    "        req_json = self._get_data(\n",
    "            url=TrendReq.REALTIME_TRENDING_SEARCHES_URL,\n",
    "            method=TrendReq.GET_METHOD,\n",
    "            trim_chars=5,\n",
    "            params=forms\n",
    "        )['storySummaries']['trendingStories']\n",
    "\n",
    "        # parse the returned json\n",
    "        wanted_keys = [\"entityNames\", \"title\"]\n",
    "\n",
    "        final_json = [{ key: ts[key] for key in ts.keys() if key in wanted_keys} for ts in req_json ]\n",
    "\n",
    "        result_df = pd.DataFrame(final_json)\n",
    "\n",
    "        return result_df\n",
    "\n",
    "    def top_charts(self, date, hl='en-US', tz=300, geo='GLOBAL'):\n",
    "        \"\"\"Request data from Google's Top Charts section and return a dataframe\"\"\"\n",
    "\n",
    "        try:\n",
    "            date = int(date)\n",
    "        except:\n",
    "            raise ValueError(\n",
    "                'The date must be a year with format YYYY. See https://github.com/GeneralMills/pytrends/issues/355')\n",
    "\n",
    "        # create the payload\n",
    "        chart_payload = {'hl': hl, 'tz': tz, 'date': date, 'geo': geo,\n",
    "                         'isMobile': False}\n",
    "\n",
    "        # make the request and parse the returned json\n",
    "        req_json = self._get_data(\n",
    "            url=TrendReq.TOP_CHARTS_URL,\n",
    "            method=TrendReq.GET_METHOD,\n",
    "            trim_chars=5,\n",
    "            params=chart_payload\n",
    "        )\n",
    "        try:\n",
    "            df = pd.DataFrame(req_json['topCharts'][0]['listItems'])\n",
    "        except IndexError:\n",
    "            df = None\n",
    "        return df\n",
    "\n",
    "    def suggestions(self, keyword):\n",
    "        \"\"\"Request data from Google's Keyword Suggestion dropdown and return a dictionary\"\"\"\n",
    "\n",
    "        # make the request\n",
    "        kw_param = quote(keyword)\n",
    "        parameters = {'hl': self.hl}\n",
    "\n",
    "        req_json = self._get_data(\n",
    "            url=TrendReq.SUGGESTIONS_URL + kw_param,\n",
    "            params=parameters,\n",
    "            method=TrendReq.GET_METHOD,\n",
    "            trim_chars=5\n",
    "        )['default']['topics']\n",
    "        return req_json\n",
    "\n",
    "    def categories(self):\n",
    "        \"\"\"Request available categories data from Google's API and return a dictionary\"\"\"\n",
    "\n",
    "        params = {'hl': self.hl}\n",
    "\n",
    "        req_json = self._get_data(\n",
    "            url=TrendReq.CATEGORIES_URL,\n",
    "            params=params,\n",
    "            method=TrendReq.GET_METHOD,\n",
    "            trim_chars=5\n",
    "        )\n",
    "        return req_json\n",
    "\n",
    "    def get_historical_interest(self, *args, **kwargs):\n",
    "        raise NotImplementedError(\n",
    "            \"\"\"This method has been removed for incorrectness. It will be removed completely in v5.\n",
    "If you'd like similar functionality, please try implementing it yourself and consider submitting a pull request to add it to pytrends.\n",
    "          \n",
    "There is discussion at:\n",
    "https://github.com/GeneralMills/pytrends/pull/542\"\"\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pytrends\n",
      "Version: 4.9.2\n",
      "Summary: Pseudo API for Google Trends\n",
      "Home-page: \n",
      "Author: John Hogue, Burton DeWilde\n",
      "Author-email: dreyco676@gmail.com\n",
      "License: Apache 2.0\n",
      "Location: C:\\Users\\Lautaro\\anaconda3\\envs\\EntornoV\\Lib\\site-packages\n",
      "Requires: lxml, pandas, requests\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show pytrends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptr = TrendReq(hl='es',retries=3, backoff_factor=20)\n",
    "kw_list = [\"End of world\",\"Climate change\",\"Earthquake\",\"Tsunami\"]\n",
    "ptr.build_payload(kw_list, cat=0, timeframe='today 5-y', geo='AR', gprop='')\n",
    "#pd = ptr.interest_over_time()\n",
    "#pd.reset_index(inplace = True)\n",
    "#df = pd[['uber']]\n",
    "#df.columns = ['Week','Uber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>End of world</th>\n",
       "      <th>Climate change</th>\n",
       "      <th>Earthquake</th>\n",
       "      <th>Tsunami</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geoName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Buenos Aires</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Catamarca</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chaco</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chubut</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ciudad Autónoma de Buenos Aires</th>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corrientes</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Córdoba</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entre Ríos</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Formosa</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jujuy</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>La Pampa</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>La Rioja</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mendoza</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Misiónes</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neuquén</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Río Negro</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salta</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Juan</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Luis</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Santa Cruz</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Santa Fe</th>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Santiago del Estero</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tierra del Fuego</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tucumán</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 End of world  Climate change  Earthquake  \\\n",
       "geoName                                                                     \n",
       "Buenos Aires                               16               5           6   \n",
       "Catamarca                                   0               0           0   \n",
       "Chaco                                       0               3           0   \n",
       "Chubut                                      0               9           9   \n",
       "Ciudad Autónoma de Buenos Aires            19              12          12   \n",
       "Corrientes                                  0               4           3   \n",
       "Córdoba                                    15               5           7   \n",
       "Entre Ríos                                  0               2           6   \n",
       "Formosa                                     0               0           0   \n",
       "Jujuy                                       0               0           6   \n",
       "La Pampa                                    0               4           0   \n",
       "La Rioja                                    0               0           5   \n",
       "Mendoza                                     0               5          22   \n",
       "Misiónes                                    0               4           6   \n",
       "Neuquén                                     0               4          10   \n",
       "Río Negro                                   0               9          12   \n",
       "Salta                                       0               4          14   \n",
       "San Juan                                    0               5          21   \n",
       "San Luis                                    0               4           7   \n",
       "Santa Cruz                                  0               0           9   \n",
       "Santa Fe                                   17               5           6   \n",
       "Santiago del Estero                         0               0           0   \n",
       "Tierra del Fuego                            0               0          11   \n",
       "Tucumán                                     0               4           7   \n",
       "\n",
       "                                 Tsunami  \n",
       "geoName                                   \n",
       "Buenos Aires                          73  \n",
       "Catamarca                            100  \n",
       "Chaco                                 97  \n",
       "Chubut                                82  \n",
       "Ciudad Autónoma de Buenos Aires       57  \n",
       "Corrientes                            93  \n",
       "Córdoba                               73  \n",
       "Entre Ríos                            92  \n",
       "Formosa                              100  \n",
       "Jujuy                                 94  \n",
       "La Pampa                              96  \n",
       "La Rioja                              95  \n",
       "Mendoza                               73  \n",
       "Misiónes                              90  \n",
       "Neuquén                               86  \n",
       "Río Negro                             79  \n",
       "Salta                                 82  \n",
       "San Juan                              74  \n",
       "San Luis                              89  \n",
       "Santa Cruz                            91  \n",
       "Santa Fe                              72  \n",
       "Santiago del Estero                  100  \n",
       "Tierra del Fuego                      89  \n",
       "Tucumán                               89  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptr.interest_by_region()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>End of world</th>\n",
       "      <th>Climate change</th>\n",
       "      <th>Earthquake</th>\n",
       "      <th>Tsunami</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geoName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Buenos Aires</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Catamarca</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chaco</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chubut</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ciudad Autónoma de Buenos Aires</th>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corrientes</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Córdoba</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entre Ríos</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Formosa</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jujuy</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>La Pampa</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>La Rioja</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mendoza</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Misiónes</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neuquén</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Río Negro</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salta</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Juan</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Luis</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Santa Cruz</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Santa Fe</th>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Santiago del Estero</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tierra del Fuego</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tucumán</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 End of world  Climate change  Earthquake  \\\n",
       "geoName                                                                     \n",
       "Buenos Aires                               16               5           6   \n",
       "Catamarca                                   0               0           0   \n",
       "Chaco                                       0               3           0   \n",
       "Chubut                                      0               9           9   \n",
       "Ciudad Autónoma de Buenos Aires            19              12          12   \n",
       "Corrientes                                  0               4           3   \n",
       "Córdoba                                    15               5           7   \n",
       "Entre Ríos                                  0               2           6   \n",
       "Formosa                                     0               0           0   \n",
       "Jujuy                                       0               0           6   \n",
       "La Pampa                                    0               4           0   \n",
       "La Rioja                                    0               0           5   \n",
       "Mendoza                                     0               5          22   \n",
       "Misiónes                                    0               4           6   \n",
       "Neuquén                                     0               4          10   \n",
       "Río Negro                                   0               9          12   \n",
       "Salta                                       0               4          14   \n",
       "San Juan                                    0               5          21   \n",
       "San Luis                                    0               4           7   \n",
       "Santa Cruz                                  0               0           9   \n",
       "Santa Fe                                   17               5           6   \n",
       "Santiago del Estero                         0               0           0   \n",
       "Tierra del Fuego                            0               0          11   \n",
       "Tucumán                                     0               4           7   \n",
       "\n",
       "                                 Tsunami  \n",
       "geoName                                   \n",
       "Buenos Aires                          73  \n",
       "Catamarca                            100  \n",
       "Chaco                                 97  \n",
       "Chubut                                82  \n",
       "Ciudad Autónoma de Buenos Aires       57  \n",
       "Corrientes                            93  \n",
       "Córdoba                               73  \n",
       "Entre Ríos                            92  \n",
       "Formosa                              100  \n",
       "Jujuy                                 94  \n",
       "La Pampa                              96  \n",
       "La Rioja                              95  \n",
       "Mendoza                               73  \n",
       "Misiónes                              90  \n",
       "Neuquén                               86  \n",
       "Río Negro                             79  \n",
       "Salta                                 82  \n",
       "San Juan                              74  \n",
       "San Luis                              89  \n",
       "Santa Cruz                            91  \n",
       "Santa Fe                              72  \n",
       "Santiago del Estero                  100  \n",
       "Tierra del Fuego                      89  \n",
       "Tucumán                               89  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1=ptr.interest_by_region()\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(t1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EntornoV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
